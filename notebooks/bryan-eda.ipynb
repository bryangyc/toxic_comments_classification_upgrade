{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"../data/raw/combined_jigsaw_comments.csv\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 50)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>comment_text</th><th>split</th><th>created_date</th><th>publication_id</th><th>parent_id</th><th>article_id</th><th>rating</th><th>funny</th><th>wow</th><th>sad</th><th>likes</th><th>disagree</th><th>toxicity</th><th>severe_toxicity</th><th>obscene</th><th>sexual_explicit</th><th>identity_attack</th><th>insult</th><th>threat</th><th>male</th><th>female</th><th>transgender</th><th>other_gender</th><th>heterosexual</th><th>homosexual_gay_or_lesbian</th><th>bisexual</th><th>other_sexual_orientation</th><th>christian</th><th>jewish</th><th>muslim</th><th>hindu</th><th>buddhist</th><th>atheist</th><th>other_religion</th><th>black</th><th>white</th><th>asian</th><th>latino</th><th>other_race_or_ethnicity</th><th>physical_disability</th><th>intellectual_or_learning_disability</th><th>psychiatric_or_mental_illness</th><th>other_disability</th><th>identity_annotator_count</th><th>toxicity_annotator_count</th><th>toxic</th><th>severe_toxic</th><th>identity_hate</th><th>lang</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1083994</td><td>&quot;He got his monâ€¦</td><td>&quot;train&quot;</td><td>&quot;2017-03-06 15:â€¦</td><td>21.0</td><td>null</td><td>317120.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.373134</td><td>0.044776</td><td>0.089552</td><td>0.014925</td><td>0.0</td><td>0.343284</td><td>0.014925</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>67.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>650904</td><td>&quot;Mad dog will sâ€¦</td><td>&quot;train&quot;</td><td>&quot;2016-12-02 16:â€¦</td><td>21.0</td><td>null</td><td>154086.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>2.0</td><td>0.0</td><td>0.605263</td><td>0.013158</td><td>0.065789</td><td>0.013158</td><td>0.092105</td><td>0.565789</td><td>0.065789</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>76.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>5902188</td><td>&quot;And Trump contâ€¦</td><td>&quot;train&quot;</td><td>&quot;2017-09-05 19:â€¦</td><td>55.0</td><td>null</td><td>374342.0</td><td>&quot;approved&quot;</td><td>1.0</td><td>0.0</td><td>2.0</td><td>3.0</td><td>7.0</td><td>0.666667</td><td>0.015873</td><td>0.031746</td><td>0.0</td><td>0.047619</td><td>0.666667</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>63.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>7084460</td><td>&quot;&quot;while arrestiâ€¦</td><td>&quot;test&quot;</td><td>&quot;2016-11-01 16:â€¦</td><td>13.0</td><td>null</td><td>149218.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.815789</td><td>0.065789</td><td>0.552632</td><td>0.592105</td><td>0.0</td><td>0.684211</td><td>0.105263</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>76.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>5410943</td><td>&quot;Tucker and Pauâ€¦</td><td>&quot;train&quot;</td><td>&quot;2017-06-14 05:â€¦</td><td>21.0</td><td>null</td><td>344096.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.55</td><td>0.0375</td><td>0.3375</td><td>0.275</td><td>0.0375</td><td>0.4875</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>80.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 50)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ id      â”† comment_text  â”† split â”† created_date  â”† â€¦ â”† toxic â”† severe_toxic â”† identity_hat â”† lang â”‚\n",
       "â”‚ ---     â”† ---           â”† ---   â”† ---           â”†   â”† ---   â”† ---          â”† e            â”† ---  â”‚\n",
       "â”‚ i64     â”† str           â”† str   â”† str           â”†   â”† str   â”† str          â”† ---          â”† str  â”‚\n",
       "â”‚         â”†               â”†       â”†               â”†   â”†       â”†              â”† str          â”†      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•¡\n",
       "â”‚ 1083994 â”† He got his    â”† train â”† 2017-03-06    â”† â€¦ â”† null  â”† null         â”† null         â”† null â”‚\n",
       "â”‚         â”† money... now  â”†       â”† 15:21:53.6752 â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚         â”† he lies â€¦     â”†       â”† 41+00         â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚ 650904  â”† Mad dog will  â”† train â”† 2016-12-02    â”† â€¦ â”† null  â”† null         â”† null         â”† null â”‚\n",
       "â”‚         â”† surely put    â”†       â”† 16:44:21.3295 â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚         â”† the libeâ€¦     â”†       â”† 35+00         â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚ 5902188 â”† And Trump     â”† train â”† 2017-09-05    â”† â€¦ â”† null  â”† null         â”† null         â”† null â”‚\n",
       "â”‚         â”† continues his â”†       â”† 19:05:32.3413 â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚         â”† lifelongâ€¦     â”†       â”† 60+00         â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚ 7084460 â”† \"while        â”† test  â”† 2016-11-01    â”† â€¦ â”† null  â”† null         â”† null         â”† null â”‚\n",
       "â”‚         â”† arresting a   â”†       â”† 16:53:33.5616 â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚         â”† man for       â”†       â”† 31+00         â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚         â”† resisâ€¦        â”†       â”†               â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚ 5410943 â”† Tucker and    â”† train â”† 2017-06-14    â”† â€¦ â”† null  â”† null         â”† null         â”† null â”‚\n",
       "â”‚         â”† Paul are both â”†       â”† 05:08:21.9973 â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â”‚         â”† total bâ€¦      â”†       â”† 15+00         â”†   â”†       â”†              â”†              â”†      â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 51)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>id</th><th>comment_text</th><th>split</th><th>created_date</th><th>publication_id</th><th>parent_id</th><th>article_id</th><th>rating</th><th>funny</th><th>wow</th><th>sad</th><th>likes</th><th>disagree</th><th>toxicity</th><th>severe_toxicity</th><th>obscene</th><th>sexual_explicit</th><th>identity_attack</th><th>insult</th><th>threat</th><th>male</th><th>female</th><th>transgender</th><th>other_gender</th><th>heterosexual</th><th>homosexual_gay_or_lesbian</th><th>bisexual</th><th>other_sexual_orientation</th><th>christian</th><th>jewish</th><th>muslim</th><th>hindu</th><th>buddhist</th><th>atheist</th><th>other_religion</th><th>black</th><th>white</th><th>asian</th><th>latino</th><th>other_race_or_ethnicity</th><th>physical_disability</th><th>intellectual_or_learning_disability</th><th>psychiatric_or_mental_illness</th><th>other_disability</th><th>identity_annotator_count</th><th>toxicity_annotator_count</th><th>toxic</th><th>severe_toxic</th><th>identity_hate</th><th>lang</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>1.999561e6</td><td>&quot;2047040&quot;</td><td>&quot;1999516&quot;</td><td>&quot;1999516&quot;</td><td>1.999516e6</td><td>1.134709e6</td><td>1.999516e6</td><td>&quot;1999516&quot;</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>2.04704e6</td><td>1.999516e6</td><td>1.999516e6</td><td>2.04704e6</td><td>2.04704e6</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>1.999516e6</td><td>1.999516e6</td><td>&quot;47524&quot;</td><td>&quot;47524&quot;</td><td>&quot;47524&quot;</td><td>&quot;0&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>47480.0</td><td>&quot;1&quot;</td><td>&quot;47525&quot;</td><td>&quot;47525&quot;</td><td>47525.0</td><td>912332.0</td><td>47525.0</td><td>&quot;47525&quot;</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>1.0</td><td>47525.0</td><td>47525.0</td><td>1.0</td><td>1.0</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>47525.0</td><td>47525.0</td><td>&quot;1999517&quot;</td><td>&quot;1999517&quot;</td><td>&quot;1999517&quot;</td><td>&quot;2047041&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>8.6318e10</td><td>null</td><td>null</td><td>null</td><td>49.889973</td><td>3.7151e6</td><td>281025.723914</td><td>null</td><td>0.277669</td><td>0.044372</td><td>0.108929</td><td>2.441188</td><td>0.580815</td><td>0.102924</td><td>0.004581</td><td>0.0148</td><td>0.006562</td><td>0.022549</td><td>0.080399</td><td>0.009144</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.431667</td><td>8.77572</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>2.0846e13</td><td>null</td><td>null</td><td>null</td><td>27.718947</td><td>2.4515e6</td><td>104077.813356</td><td>null</td><td>1.054819</td><td>0.245864</td><td>0.455557</td><td>4.712994</td><td>1.854332</td><td>0.197039</td><td>0.022858</td><td>0.0727</td><td>0.045112</td><td>0.07854</td><td>0.177208</td><td>0.049567</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>17.635931</td><td>43.31605</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>59848.0</td><td>&quot;\u0010Canada is norâ€¦</td><td>&quot;test&quot;</td><td>&quot;2015-09-29 10:â€¦</td><td>2.0</td><td>61006.0</td><td>2006.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>0.0</td><td>3.0</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>856592.0</td><td>null</td><td>null</td><td>null</td><td>21.0</td><td>793011.0</td><td>160004.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>4.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>5.340251e6</td><td>null</td><td>null</td><td>null</td><td>54.0</td><td>5.217531e6</td><td>331925.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>4.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>5.95582e6</td><td>null</td><td>null</td><td>null</td><td>54.0</td><td>5.774684e6</td><td>366227.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>0.166667</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>6.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>7.5133e15</td><td>&quot;ğŸ¤£gotta love itâ€¦</td><td>&quot;train&quot;</td><td>&quot;2017-11-11 01:â€¦</td><td>115.0</td><td>6.333965e6</td><td>399544.0</td><td>&quot;rejected&quot;</td><td>102.0</td><td>21.0</td><td>31.0</td><td>300.0</td><td>187.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;0.75&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;0.75&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;0.6&quot;</td><td>1866.0</td><td>4936.0</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 51)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ statistic  â”† id         â”† comment_te â”† split   â”† â€¦ â”† toxic   â”† severe_tox â”† identity_h â”† lang    â”‚\n",
       "â”‚ ---        â”† ---        â”† xt         â”† ---     â”†   â”† ---     â”† ic         â”† ate        â”† ---     â”‚\n",
       "â”‚ str        â”† f64        â”† ---        â”† str     â”†   â”† str     â”† ---        â”† ---        â”† str     â”‚\n",
       "â”‚            â”†            â”† str        â”†         â”†   â”†         â”† str        â”† str        â”†         â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ count      â”† 1.999561e6 â”† 2047040    â”† 1999516 â”† â€¦ â”† 47524   â”† 47524      â”† 47524      â”† 0       â”‚\n",
       "â”‚ null_count â”† 47480.0    â”† 1          â”† 47525   â”† â€¦ â”† 1999517 â”† 1999517    â”† 1999517    â”† 2047041 â”‚\n",
       "â”‚ mean       â”† 8.6318e10  â”† null       â”† null    â”† â€¦ â”† null    â”† null       â”† null       â”† null    â”‚\n",
       "â”‚ std        â”† 2.0846e13  â”† null       â”† null    â”† â€¦ â”† null    â”† null       â”† null       â”† null    â”‚\n",
       "â”‚ min        â”† 59848.0    â”† \u0010Canada is  â”† test    â”† â€¦ â”† 0.0     â”† 0.0        â”† 0.0        â”† null    â”‚\n",
       "â”‚            â”†            â”† north of   â”†         â”†   â”†         â”†            â”†            â”†         â”‚\n",
       "â”‚            â”†            â”† the USA    â”†         â”†   â”†         â”†            â”†            â”†         â”‚\n",
       "â”‚            â”†            â”† bordâ€¦      â”†         â”†   â”†         â”†            â”†            â”†         â”‚\n",
       "â”‚ 25%        â”† 856592.0   â”† null       â”† null    â”† â€¦ â”† null    â”† null       â”† null       â”† null    â”‚\n",
       "â”‚ 50%        â”† 5.340251e6 â”† null       â”† null    â”† â€¦ â”† null    â”† null       â”† null       â”† null    â”‚\n",
       "â”‚ 75%        â”† 5.95582e6  â”† null       â”† null    â”† â€¦ â”† null    â”† null       â”† null       â”† null    â”‚\n",
       "â”‚ max        â”† 7.5133e15  â”† ğŸ¤£gotta    â”† train   â”† â€¦ â”† 1.0     â”† 1.0        â”† 1.0        â”† null    â”‚\n",
       "â”‚            â”†            â”† love it!   â”†         â”†   â”†         â”†            â”†            â”†         â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.with_columns(pl.all().is_null().name.suffix(\"_isnull\")).count()  # nan != null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = df.select(\n",
    "    df[[\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",'sexual_explicit']]\n",
    "    ).max_horizontal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_047_041, 51)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>comment_text</th><th>split</th><th>created_date</th><th>publication_id</th><th>parent_id</th><th>article_id</th><th>rating</th><th>funny</th><th>wow</th><th>sad</th><th>likes</th><th>disagree</th><th>toxicity</th><th>severe_toxicity</th><th>obscene</th><th>sexual_explicit</th><th>identity_attack</th><th>insult</th><th>threat</th><th>male</th><th>female</th><th>transgender</th><th>other_gender</th><th>heterosexual</th><th>homosexual_gay_or_lesbian</th><th>bisexual</th><th>other_sexual_orientation</th><th>christian</th><th>jewish</th><th>muslim</th><th>hindu</th><th>buddhist</th><th>atheist</th><th>other_religion</th><th>black</th><th>white</th><th>asian</th><th>latino</th><th>other_race_or_ethnicity</th><th>physical_disability</th><th>intellectual_or_learning_disability</th><th>psychiatric_or_mental_illness</th><th>other_disability</th><th>identity_annotator_count</th><th>toxicity_annotator_count</th><th>toxic</th><th>severe_toxic</th><th>identity_hate</th><th>lang</th><th>max</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>1083994</td><td>&quot;He got his monâ€¦</td><td>&quot;train&quot;</td><td>&quot;2017-03-06 15:â€¦</td><td>21.0</td><td>null</td><td>317120.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.373134</td><td>0.044776</td><td>0.089552</td><td>0.014925</td><td>0.0</td><td>0.343284</td><td>0.014925</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>67.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.373134</td></tr><tr><td>650904</td><td>&quot;Mad dog will sâ€¦</td><td>&quot;train&quot;</td><td>&quot;2016-12-02 16:â€¦</td><td>21.0</td><td>null</td><td>154086.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>2.0</td><td>0.0</td><td>0.605263</td><td>0.013158</td><td>0.065789</td><td>0.013158</td><td>0.092105</td><td>0.565789</td><td>0.065789</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>76.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.605263</td></tr><tr><td>5902188</td><td>&quot;And Trump contâ€¦</td><td>&quot;train&quot;</td><td>&quot;2017-09-05 19:â€¦</td><td>55.0</td><td>null</td><td>374342.0</td><td>&quot;approved&quot;</td><td>1.0</td><td>0.0</td><td>2.0</td><td>3.0</td><td>7.0</td><td>0.666667</td><td>0.015873</td><td>0.031746</td><td>0.0</td><td>0.047619</td><td>0.666667</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>63.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.666667</td></tr><tr><td>7084460</td><td>&quot;&quot;while arrestiâ€¦</td><td>&quot;test&quot;</td><td>&quot;2016-11-01 16:â€¦</td><td>13.0</td><td>null</td><td>149218.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.815789</td><td>0.065789</td><td>0.552632</td><td>0.592105</td><td>0.0</td><td>0.684211</td><td>0.105263</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>76.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.815789</td></tr><tr><td>5410943</td><td>&quot;Tucker and Pauâ€¦</td><td>&quot;train&quot;</td><td>&quot;2017-06-14 05:â€¦</td><td>21.0</td><td>null</td><td>344096.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.55</td><td>0.0375</td><td>0.3375</td><td>0.275</td><td>0.0375</td><td>0.4875</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>80.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.55</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>null</td><td>&quot;&quot;\n",
       "\n",
       " Ahirs (Abhâ€¦</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td><td>0.0</td></tr><tr><td>null</td><td>&quot;On User:Timothâ€¦</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td><td>0.0</td></tr><tr><td>null</td><td>&quot;Thank you veryâ€¦</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td><td>0.0</td></tr><tr><td>null</td><td>&quot;was hoping youâ€¦</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td><td>0.0</td></tr><tr><td>null</td><td>&quot;&quot;\n",
       "\n",
       " Congratulaâ€¦</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_047_041, 51)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ id      â”† comment_text â”† split â”† created_date â”† â€¦ â”† severe_toxic â”† identity_ha â”† lang â”† max      â”‚\n",
       "â”‚ ---     â”† ---          â”† ---   â”† ---          â”†   â”† ---          â”† te          â”† ---  â”† ---      â”‚\n",
       "â”‚ i64     â”† str          â”† str   â”† str          â”†   â”† str          â”† ---         â”† str  â”† f64      â”‚\n",
       "â”‚         â”†              â”†       â”†              â”†   â”†              â”† str         â”†      â”†          â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1083994 â”† He got his   â”† train â”† 2017-03-06   â”† â€¦ â”† null         â”† null        â”† null â”† 0.373134 â”‚\n",
       "â”‚         â”† money... now â”†       â”† 15:21:53.675 â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† he lies â€¦    â”†       â”† 241+00       â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚ 650904  â”† Mad dog will â”† train â”† 2016-12-02   â”† â€¦ â”† null         â”† null        â”† null â”† 0.605263 â”‚\n",
       "â”‚         â”† surely put   â”†       â”† 16:44:21.329 â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† the libeâ€¦    â”†       â”† 535+00       â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚ 5902188 â”† And Trump    â”† train â”† 2017-09-05   â”† â€¦ â”† null         â”† null        â”† null â”† 0.666667 â”‚\n",
       "â”‚         â”† continues    â”†       â”† 19:05:32.341 â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† his          â”†       â”† 360+00       â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† lifelongâ€¦    â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚ 7084460 â”† \"while       â”† test  â”† 2016-11-01   â”† â€¦ â”† null         â”† null        â”† null â”† 0.815789 â”‚\n",
       "â”‚         â”† arresting a  â”†       â”† 16:53:33.561 â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† man for      â”†       â”† 631+00       â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† resisâ€¦       â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚ 5410943 â”† Tucker and   â”† train â”† 2017-06-14   â”† â€¦ â”† null         â”† null        â”† null â”† 0.55     â”‚\n",
       "â”‚         â”† Paul are     â”†       â”† 05:08:21.997 â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† both total   â”†       â”† 315+00       â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† bâ€¦           â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚ â€¦       â”† â€¦            â”† â€¦     â”† â€¦            â”† â€¦ â”† â€¦            â”† â€¦           â”† â€¦    â”† â€¦        â”‚\n",
       "â”‚ null    â”† \"            â”† null  â”† null         â”† â€¦ â”† 0.0          â”† 0.0         â”† null â”† 0.0      â”‚\n",
       "â”‚         â”†              â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† Ahirs        â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† (Abhiras)    â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† came from    â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† Eaâ€¦          â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚ null    â”† On           â”† null  â”† null         â”† â€¦ â”† 0.0          â”† 0.0         â”† null â”† 0.0      â”‚\n",
       "â”‚         â”† User:Timothy â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† Usher        â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”†              â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† Assalamu â€¦   â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚ null    â”† Thank you    â”† null  â”† null         â”† â€¦ â”† 0.0          â”† 0.0         â”† null â”† 0.0      â”‚\n",
       "â”‚         â”† very much.   â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† Since Ingleâ€¦ â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚ null    â”† was hoping   â”† null  â”† null         â”† â€¦ â”† 0.0          â”† 0.0         â”† null â”† 0.0      â”‚\n",
       "â”‚         â”† your the     â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† type of      â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† rougâ€¦        â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚ null    â”† \"            â”† null  â”† null         â”† â€¦ â”† null         â”† null        â”† null â”† null     â”‚\n",
       "â”‚         â”†              â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† Congratulati â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† ons. Here    â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â”‚         â”† are whâ€¦      â”†       â”†              â”†   â”†              â”†             â”†      â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.with_columns(\n",
    "    df.select(\n",
    "    df[[\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",'sexual_explicit']]\n",
    "    ).max_horizontal()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polars import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"comment_text\", \"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",\"sexual_explicit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_047_041, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>comment_text</th><th>toxicity</th><th>severe_toxicity</th><th>obscene</th><th>threat</th><th>insult</th><th>identity_attack</th><th>sexual_explicit</th><th>sum</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;He got his monâ€¦</td><td>0.373134</td><td>0.044776</td><td>0.089552</td><td>0.014925</td><td>0.343284</td><td>0.0</td><td>0.014925</td><td>0.373134</td></tr><tr><td>&quot;Mad dog will sâ€¦</td><td>0.605263</td><td>0.013158</td><td>0.065789</td><td>0.065789</td><td>0.565789</td><td>0.092105</td><td>0.013158</td><td>0.605263</td></tr><tr><td>&quot;And Trump contâ€¦</td><td>0.666667</td><td>0.015873</td><td>0.031746</td><td>0.0</td><td>0.666667</td><td>0.047619</td><td>0.0</td><td>0.666667</td></tr><tr><td>&quot;&quot;while arrestiâ€¦</td><td>0.815789</td><td>0.065789</td><td>0.552632</td><td>0.105263</td><td>0.684211</td><td>0.0</td><td>0.592105</td><td>0.815789</td></tr><tr><td>&quot;Tucker and Pauâ€¦</td><td>0.55</td><td>0.0375</td><td>0.3375</td><td>0.0</td><td>0.4875</td><td>0.0375</td><td>0.275</td><td>0.55</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;&quot;\n",
       "\n",
       " Ahirs (Abhâ€¦</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>&quot;On User:Timothâ€¦</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>&quot;Thank you veryâ€¦</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>&quot;was hoping youâ€¦</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>&quot;&quot;\n",
       "\n",
       " Congratulaâ€¦</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_047_041, 9)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ comment_te â”† toxicity â”† severe_tox â”† obscene  â”† â€¦ â”† insult   â”† identity_a â”† sexual_ex â”† sum      â”‚\n",
       "â”‚ xt         â”† ---      â”† icity      â”† ---      â”†   â”† ---      â”† ttack      â”† plicit    â”† ---      â”‚\n",
       "â”‚ ---        â”† f64      â”† ---        â”† f64      â”†   â”† f64      â”† ---        â”† ---       â”† f64      â”‚\n",
       "â”‚ str        â”†          â”† f64        â”†          â”†   â”†          â”† f64        â”† f64       â”†          â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ He got his â”† 0.373134 â”† 0.044776   â”† 0.089552 â”† â€¦ â”† 0.343284 â”† 0.0        â”† 0.014925  â”† 0.373134 â”‚\n",
       "â”‚ money...   â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ now he     â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ lies â€¦     â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Mad dog    â”† 0.605263 â”† 0.013158   â”† 0.065789 â”† â€¦ â”† 0.565789 â”† 0.092105   â”† 0.013158  â”† 0.605263 â”‚\n",
       "â”‚ will       â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ surely put â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ the libeâ€¦  â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ And Trump  â”† 0.666667 â”† 0.015873   â”† 0.031746 â”† â€¦ â”† 0.666667 â”† 0.047619   â”† 0.0       â”† 0.666667 â”‚\n",
       "â”‚ continues  â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ his        â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ lifelongâ€¦  â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ \"while     â”† 0.815789 â”† 0.065789   â”† 0.552632 â”† â€¦ â”† 0.684211 â”† 0.0        â”† 0.592105  â”† 0.815789 â”‚\n",
       "â”‚ arresting  â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ a man for  â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ resisâ€¦     â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Tucker and â”† 0.55     â”† 0.0375     â”† 0.3375   â”† â€¦ â”† 0.4875   â”† 0.0375     â”† 0.275     â”† 0.55     â”‚\n",
       "â”‚ Paul are   â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ both total â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ bâ€¦         â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ â€¦          â”† â€¦        â”† â€¦          â”† â€¦        â”† â€¦ â”† â€¦        â”† â€¦          â”† â€¦         â”† â€¦        â”‚\n",
       "â”‚ \"          â”† null     â”† null       â”† 0.0      â”† â€¦ â”† 0.0      â”† null       â”† null      â”† 0.0      â”‚\n",
       "â”‚            â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Ahirs      â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ (Abhiras)  â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ came from  â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Eaâ€¦        â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ On User:Ti â”† null     â”† null       â”† 0.0      â”† â€¦ â”† 0.0      â”† null       â”† null      â”† 0.0      â”‚\n",
       "â”‚ mothy      â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Usher      â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚            â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Assalamu â€¦ â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Thank you  â”† null     â”† null       â”† 0.0      â”† â€¦ â”† 0.0      â”† null       â”† null      â”† 0.0      â”‚\n",
       "â”‚ very much. â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Since      â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Ingleâ€¦     â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ was hoping â”† null     â”† null       â”† 0.0      â”† â€¦ â”† 0.0      â”† null       â”† null      â”† 0.0      â”‚\n",
       "â”‚ your the   â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ type of    â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ rougâ€¦      â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ \"          â”† null     â”† null       â”† null     â”† â€¦ â”† null     â”† null       â”† null      â”† null     â”‚\n",
       "â”‚            â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Congratula â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ tions.     â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ Here are   â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â”‚ whâ€¦        â”†          â”†            â”†          â”†   â”†          â”†            â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_t_cols = [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",'sexual_explicit']\n",
    "\n",
    "df2.with_columns(\n",
    "    sum=pl.max_horizontal([df2[t] for t in temp_t_cols]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select(\"toxicity\").agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = df.select(\"toxicity\")\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.histplot(temp_df)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_df = pl.scan_csv(\"../data/raw/combined_jigsaw_comments.csv\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"340pt\" height=\"61pt\" viewBox=\"0.00 0.00 340.00 61.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 57)\">\n",
       "<title>polars_query</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-57 336,-57 336,4 -4,4\"/>\n",
       "<!-- [Csv SCAN ../data/raw/combined_jigsaw_comments.csv;\n",
       "Ï€ */50;\n",
       "Ïƒ &#45;] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>[Csv SCAN ../data/raw/combined_jigsaw_comments.csv;\n",
       "Ï€ */50;\n",
       "Ïƒ -]</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"332,-53 0,-53 0,0 332,0 332,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">[Csv SCAN ../data/raw/combined_jigsaw_comments.csv;</text>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Ï€ */50;</text>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">Ïƒ -]</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lazy_df.show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', Int64),\n",
       "             ('comment_text', String),\n",
       "             ('split', String),\n",
       "             ('created_date', String),\n",
       "             ('publication_id', Float64),\n",
       "             ('parent_id', Float64),\n",
       "             ('article_id', Float64),\n",
       "             ('rating', String),\n",
       "             ('funny', Float64),\n",
       "             ('wow', Float64),\n",
       "             ('sad', Float64),\n",
       "             ('likes', Float64),\n",
       "             ('disagree', Float64),\n",
       "             ('toxicity', Float64),\n",
       "             ('severe_toxicity', Float64),\n",
       "             ('obscene', Float64),\n",
       "             ('sexual_explicit', Float64),\n",
       "             ('identity_attack', Float64),\n",
       "             ('insult', Float64),\n",
       "             ('threat', Float64),\n",
       "             ('male', String),\n",
       "             ('female', String),\n",
       "             ('transgender', String),\n",
       "             ('other_gender', String),\n",
       "             ('heterosexual', String),\n",
       "             ('homosexual_gay_or_lesbian', String),\n",
       "             ('bisexual', String),\n",
       "             ('other_sexual_orientation', String),\n",
       "             ('christian', String),\n",
       "             ('jewish', String),\n",
       "             ('muslim', String),\n",
       "             ('hindu', String),\n",
       "             ('buddhist', String),\n",
       "             ('atheist', String),\n",
       "             ('other_religion', String),\n",
       "             ('black', String),\n",
       "             ('white', String),\n",
       "             ('asian', String),\n",
       "             ('latino', String),\n",
       "             ('other_race_or_ethnicity', String),\n",
       "             ('physical_disability', String),\n",
       "             ('intellectual_or_learning_disability', String),\n",
       "             ('psychiatric_or_mental_illness', String),\n",
       "             ('other_disability', String),\n",
       "             ('identity_annotator_count', Float64),\n",
       "             ('toxicity_annotator_count', Float64),\n",
       "             ('toxic', String),\n",
       "             ('severe_toxic', String),\n",
       "             ('identity_hate', String),\n",
       "             ('lang', String)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"comment_text\", \"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",\"sexual_explicit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "lazy_df = lazy_df.select(cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LazyFrame' object is not subscriptable (aside from slicing)\n\nUse `select()` or `filter()` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lazy_df \u001b[38;5;241m=\u001b[39m lazy_df\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m      2\u001b[0m     lazy_df\u001b[38;5;241m.\u001b[39mselect(\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mlazy_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoxicity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msevere_toxicity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobscene\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minsult\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43midentity_attack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msexual_explicit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m     )\u001b[38;5;241m.\u001b[39mcollect()\u001b[38;5;241m.\u001b[39mmax_horizontal()\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/polars/lazyframe/frame.py:760\u001b[0m, in \u001b[0;36mLazyFrame.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m    756\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    757\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLazyFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object is not subscriptable (aside from slicing)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUse `select()` or `filter()` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    759\u001b[0m     )\n\u001b[0;32m--> 760\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LazyPolarsSlice(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(item)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LazyFrame' object is not subscriptable (aside from slicing)\n\nUse `select()` or `filter()` instead."
     ]
    }
   ],
   "source": [
    "lazy_df = lazy_df.with_columns(\n",
    "    lazy_df.select(\n",
    "    lazy_df[[\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",'sexual_explicit']]\n",
    "    ).collect().max_horizontal().collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82255/3151280416.py:1: DtypeWarning: Columns (0,2,3,7,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../data/raw/combined_jigsaw_comments.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/raw/combined_jigsaw_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [\"comment_text\", \"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",\"sexual_explicit\"]\n",
    "cal_cols = [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",\"sexual_explicit\"]\n",
    "\n",
    "data = data[all_cols]\n",
    "\n",
    "# find max of rows\n",
    "# data[\"max_toxicity_score\"] = data[cal_cols].max(axis=1)\n",
    "# data = data.drop(columns=cal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He got his money... now he lies in wait till a...</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mad dog will surely put the liberals in mental...</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.013158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And Trump continues his lifelong cowardice by ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"while arresting a man for resisting arrest\".\\...</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxicity  \\\n",
       "0  He got his money... now he lies in wait till a...  0.373134   \n",
       "1  Mad dog will surely put the liberals in mental...  0.605263   \n",
       "2  And Trump continues his lifelong cowardice by ...  0.666667   \n",
       "3  \"while arresting a man for resisting arrest\".\\...  0.815789   \n",
       "4     Tucker and Paul are both total bad ass mofo's.  0.550000   \n",
       "\n",
       "   severe_toxicity   obscene    threat    insult  identity_attack  \\\n",
       "0         0.044776  0.089552  0.014925  0.343284         0.000000   \n",
       "1         0.013158  0.065789  0.065789  0.565789         0.092105   \n",
       "2         0.015873  0.031746  0.000000  0.666667         0.047619   \n",
       "3         0.065789  0.552632  0.105263  0.684211         0.000000   \n",
       "4         0.037500  0.337500  0.000000  0.487500         0.037500   \n",
       "\n",
       "   sexual_explicit  \n",
       "0         0.014925  \n",
       "1         0.013158  \n",
       "2         0.000000  \n",
       "3         0.592105  \n",
       "4         0.275000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TextClassificationPipeline,\n",
    ")\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"martin-ha/toxic-comment-model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, max_length=\"max_length\", truncation=True, use_fast=True, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "# print(pipeline(\"This is a test text.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryangoh/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (721) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# def data():\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     for i in range(1000):\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#         yield f\"My example {i}\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# for out in pipe(data()):\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     generated_characters += len(out[0][\"generated_text\"])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# print(i,x)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_toxicity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/base.py:1196\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1190\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1193\u001b[0m         )\n\u001b[1;32m   1194\u001b[0m     )\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/base.py:1203\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1202\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1203\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/base.py:1102\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1101\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1102\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:186\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    185\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:1002\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1002\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:814\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    812\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 814\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[1;32m    817\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:156\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[0;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[1;32m    152\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m position_ids\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand_as(input_ids)  \u001b[38;5;66;03m# (bs, max_seq_length)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43minput_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    157\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    158\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (721) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# def data():\n",
    "#     for i in range(1000):\n",
    "#         yield f\"My example {i}\"\n",
    "\n",
    "\n",
    "# pipe = pipeline(model=\"openai-community/gpt2\", device=0)\n",
    "# generated_characters = 0\n",
    "# for out in pipe(data()):\n",
    "#     generated_characters += len(out[0][\"generated_text\"])\n",
    "\n",
    "for i in data[\"comment_text\"]:\n",
    "    x = pipeline(i)\n",
    "    # print(i,x)\n",
    "    data['predicted_toxicity'] = x[0][\"label\"]\n",
    "    data[\"predicted_non_toxicity_score\"] = x[0][\"score\"]\n",
    "    # print(x[0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KeyDataset is a util that will just output the item we're interested in.\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "pipe = pipeline(model=\"hf-internal-testing/tiny-random-wav2vec2\", device=0)\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:10]\")\n",
    "\n",
    "for out in pipe(KeyDataset(dataset, \"audio\")):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TextClassificationPipeline,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from torch import cuda\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import dill as pickle\n",
    "from huggingface_hub import login, notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicModeling:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_path = \"distilbert/distilbert-base-uncased\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_path, num_labels=1\n",
    "        )\n",
    "        os.makedirs(\"./models/checkpoint\", exist_ok=True)\n",
    "        self.training_args = TrainingArguments(\n",
    "            output_dir=\"./models/checkpoint\", evaluation_strategy=\"epoch\"\n",
    "        )\n",
    "        self.metric = evaluate.load(\"mse\")\n",
    "        self.device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def tokenize_function(self, example):\n",
    "        # dataset[target_col] = dataset[target_col].astype(str)\n",
    "        return self.tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    # def _tokenize(self, dataset):\n",
    "    #     return dataset.map(self.tokenize_function, batched=True)\n",
    "\n",
    "    def _compute_metrics(self, eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        # predictions = np.argmax(logits, axis=-1)\n",
    "        predictions = logits\n",
    "        return self.metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_dataset,\n",
    "        eval_dataset,\n",
    "        target_col,\n",
    "    ):\n",
    "        # tokenized_train_function = self.tokenize_function(train_dataset, target_col)\n",
    "        # tokenized_eval_function = self.tokenize_function(eval_dataset, target_col)\n",
    "        # tokenized_function = self.tokenize_function\n",
    "        # tokenized_train_dataset = train_dataset.map(\n",
    "        #     self.tokenize_function, batched=True\n",
    "        # )\n",
    "        # tokenized_eval_dataset = eval_dataset.map(self.tokenize_function, batched=True)\n",
    "\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=self.training_args,\n",
    "            train_dataset=tokenized_train_dataset,\n",
    "            eval_dataset=tokenized_eval_dataset,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "            push_to_hub=True,\n",
    "            data_collator=self.data_collator,\n",
    "        )\n",
    "        trainer.train()\n",
    "        return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/train.pkl\", \"rb\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "f.close()\n",
    "with open(\"../data/processed/test.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_54687/1920291564.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  train_dataset = train_dataset.applymap(str)\n",
      "/tmp/ipykernel_54687/1920291564.py:4: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_dataset = test_dataset.applymap(str)\n"
     ]
    }
   ],
   "source": [
    "# notebook_login()\n",
    "tx = ToxicModeling()\n",
    "train_dataset = train_dataset.applymap(str)\n",
    "test_dataset = test_dataset.applymap(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoxicity_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoxicity_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      2\u001b[0m test_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoxicity_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m test_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoxicity_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mmap(tx\u001b[38;5;241m.\u001b[39mtokenize_function)\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10455\u001b[0m, in \u001b[0;36mDataFrame.map\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[1;32m  10453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m> 10455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10360\u001b[0m )\n\u001b[0;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10453\u001b[0m, in \u001b[0;36mDataFrame.map.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m  10452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[0;32m> 10453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mToxicModeling.tokenize_function\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, example):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# dataset[target_col] = dataset[target_col].astype(str)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "train_dataset[\"toxicity_score\"] = train_dataset[\"toxicity_score\"].astype(float)\n",
    "test_dataset[\"toxicity_score\"] = test_dataset[\"toxicity_score\"].astype(float)\n",
    "train_dataset = train_dataset.map(tx.tokenize_function)\n",
    "test_dataset = test_dataset.map(tx.tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = train_dataset.sample(10)\n",
    "test_dataset = test_dataset.sample(10)\n",
    "tx.train(\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    target_col=args[\"target_col\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
