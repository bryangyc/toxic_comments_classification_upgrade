{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"../data/raw/combined_jigsaw_comments.csv\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 50)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>comment_text</th><th>split</th><th>created_date</th><th>publication_id</th><th>parent_id</th><th>article_id</th><th>rating</th><th>funny</th><th>wow</th><th>sad</th><th>likes</th><th>disagree</th><th>toxicity</th><th>severe_toxicity</th><th>obscene</th><th>sexual_explicit</th><th>identity_attack</th><th>insult</th><th>threat</th><th>male</th><th>female</th><th>transgender</th><th>other_gender</th><th>heterosexual</th><th>homosexual_gay_or_lesbian</th><th>bisexual</th><th>other_sexual_orientation</th><th>christian</th><th>jewish</th><th>muslim</th><th>hindu</th><th>buddhist</th><th>atheist</th><th>other_religion</th><th>black</th><th>white</th><th>asian</th><th>latino</th><th>other_race_or_ethnicity</th><th>physical_disability</th><th>intellectual_or_learning_disability</th><th>psychiatric_or_mental_illness</th><th>other_disability</th><th>identity_annotator_count</th><th>toxicity_annotator_count</th><th>toxic</th><th>severe_toxic</th><th>identity_hate</th><th>lang</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1083994</td><td>&quot;He got his mon…</td><td>&quot;train&quot;</td><td>&quot;2017-03-06 15:…</td><td>21.0</td><td>null</td><td>317120.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.373134</td><td>0.044776</td><td>0.089552</td><td>0.014925</td><td>0.0</td><td>0.343284</td><td>0.014925</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>67.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>650904</td><td>&quot;Mad dog will s…</td><td>&quot;train&quot;</td><td>&quot;2016-12-02 16:…</td><td>21.0</td><td>null</td><td>154086.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>2.0</td><td>0.0</td><td>0.605263</td><td>0.013158</td><td>0.065789</td><td>0.013158</td><td>0.092105</td><td>0.565789</td><td>0.065789</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>76.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>5902188</td><td>&quot;And Trump cont…</td><td>&quot;train&quot;</td><td>&quot;2017-09-05 19:…</td><td>55.0</td><td>null</td><td>374342.0</td><td>&quot;approved&quot;</td><td>1.0</td><td>0.0</td><td>2.0</td><td>3.0</td><td>7.0</td><td>0.666667</td><td>0.015873</td><td>0.031746</td><td>0.0</td><td>0.047619</td><td>0.666667</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>63.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>7084460</td><td>&quot;&quot;while arresti…</td><td>&quot;test&quot;</td><td>&quot;2016-11-01 16:…</td><td>13.0</td><td>null</td><td>149218.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.815789</td><td>0.065789</td><td>0.552632</td><td>0.592105</td><td>0.0</td><td>0.684211</td><td>0.105263</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>76.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>5410943</td><td>&quot;Tucker and Pau…</td><td>&quot;train&quot;</td><td>&quot;2017-06-14 05:…</td><td>21.0</td><td>null</td><td>344096.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.55</td><td>0.0375</td><td>0.3375</td><td>0.275</td><td>0.0375</td><td>0.4875</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>80.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 50)\n",
       "┌─────────┬───────────────┬───────┬───────────────┬───┬───────┬──────────────┬──────────────┬──────┐\n",
       "│ id      ┆ comment_text  ┆ split ┆ created_date  ┆ … ┆ toxic ┆ severe_toxic ┆ identity_hat ┆ lang │\n",
       "│ ---     ┆ ---           ┆ ---   ┆ ---           ┆   ┆ ---   ┆ ---          ┆ e            ┆ ---  │\n",
       "│ i64     ┆ str           ┆ str   ┆ str           ┆   ┆ str   ┆ str          ┆ ---          ┆ str  │\n",
       "│         ┆               ┆       ┆               ┆   ┆       ┆              ┆ str          ┆      │\n",
       "╞═════════╪═══════════════╪═══════╪═══════════════╪═══╪═══════╪══════════════╪══════════════╪══════╡\n",
       "│ 1083994 ┆ He got his    ┆ train ┆ 2017-03-06    ┆ … ┆ null  ┆ null         ┆ null         ┆ null │\n",
       "│         ┆ money... now  ┆       ┆ 15:21:53.6752 ┆   ┆       ┆              ┆              ┆      │\n",
       "│         ┆ he lies …     ┆       ┆ 41+00         ┆   ┆       ┆              ┆              ┆      │\n",
       "│ 650904  ┆ Mad dog will  ┆ train ┆ 2016-12-02    ┆ … ┆ null  ┆ null         ┆ null         ┆ null │\n",
       "│         ┆ surely put    ┆       ┆ 16:44:21.3295 ┆   ┆       ┆              ┆              ┆      │\n",
       "│         ┆ the libe…     ┆       ┆ 35+00         ┆   ┆       ┆              ┆              ┆      │\n",
       "│ 5902188 ┆ And Trump     ┆ train ┆ 2017-09-05    ┆ … ┆ null  ┆ null         ┆ null         ┆ null │\n",
       "│         ┆ continues his ┆       ┆ 19:05:32.3413 ┆   ┆       ┆              ┆              ┆      │\n",
       "│         ┆ lifelong…     ┆       ┆ 60+00         ┆   ┆       ┆              ┆              ┆      │\n",
       "│ 7084460 ┆ \"while        ┆ test  ┆ 2016-11-01    ┆ … ┆ null  ┆ null         ┆ null         ┆ null │\n",
       "│         ┆ arresting a   ┆       ┆ 16:53:33.5616 ┆   ┆       ┆              ┆              ┆      │\n",
       "│         ┆ man for       ┆       ┆ 31+00         ┆   ┆       ┆              ┆              ┆      │\n",
       "│         ┆ resis…        ┆       ┆               ┆   ┆       ┆              ┆              ┆      │\n",
       "│ 5410943 ┆ Tucker and    ┆ train ┆ 2017-06-14    ┆ … ┆ null  ┆ null         ┆ null         ┆ null │\n",
       "│         ┆ Paul are both ┆       ┆ 05:08:21.9973 ┆   ┆       ┆              ┆              ┆      │\n",
       "│         ┆ total b…      ┆       ┆ 15+00         ┆   ┆       ┆              ┆              ┆      │\n",
       "└─────────┴───────────────┴───────┴───────────────┴───┴───────┴──────────────┴──────────────┴──────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 51)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>id</th><th>comment_text</th><th>split</th><th>created_date</th><th>publication_id</th><th>parent_id</th><th>article_id</th><th>rating</th><th>funny</th><th>wow</th><th>sad</th><th>likes</th><th>disagree</th><th>toxicity</th><th>severe_toxicity</th><th>obscene</th><th>sexual_explicit</th><th>identity_attack</th><th>insult</th><th>threat</th><th>male</th><th>female</th><th>transgender</th><th>other_gender</th><th>heterosexual</th><th>homosexual_gay_or_lesbian</th><th>bisexual</th><th>other_sexual_orientation</th><th>christian</th><th>jewish</th><th>muslim</th><th>hindu</th><th>buddhist</th><th>atheist</th><th>other_religion</th><th>black</th><th>white</th><th>asian</th><th>latino</th><th>other_race_or_ethnicity</th><th>physical_disability</th><th>intellectual_or_learning_disability</th><th>psychiatric_or_mental_illness</th><th>other_disability</th><th>identity_annotator_count</th><th>toxicity_annotator_count</th><th>toxic</th><th>severe_toxic</th><th>identity_hate</th><th>lang</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>1.999561e6</td><td>&quot;2047040&quot;</td><td>&quot;1999516&quot;</td><td>&quot;1999516&quot;</td><td>1.999516e6</td><td>1.134709e6</td><td>1.999516e6</td><td>&quot;1999516&quot;</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>1.999516e6</td><td>2.04704e6</td><td>1.999516e6</td><td>1.999516e6</td><td>2.04704e6</td><td>2.04704e6</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>&quot;448000&quot;</td><td>1.999516e6</td><td>1.999516e6</td><td>&quot;47524&quot;</td><td>&quot;47524&quot;</td><td>&quot;47524&quot;</td><td>&quot;0&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>47480.0</td><td>&quot;1&quot;</td><td>&quot;47525&quot;</td><td>&quot;47525&quot;</td><td>47525.0</td><td>912332.0</td><td>47525.0</td><td>&quot;47525&quot;</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>47525.0</td><td>1.0</td><td>47525.0</td><td>47525.0</td><td>1.0</td><td>1.0</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>&quot;1599041&quot;</td><td>47525.0</td><td>47525.0</td><td>&quot;1999517&quot;</td><td>&quot;1999517&quot;</td><td>&quot;1999517&quot;</td><td>&quot;2047041&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>8.6318e10</td><td>null</td><td>null</td><td>null</td><td>49.889973</td><td>3.7151e6</td><td>281025.723914</td><td>null</td><td>0.277669</td><td>0.044372</td><td>0.108929</td><td>2.441188</td><td>0.580815</td><td>0.102924</td><td>0.004581</td><td>0.0148</td><td>0.006562</td><td>0.022549</td><td>0.080399</td><td>0.009144</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.431667</td><td>8.77572</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>2.0846e13</td><td>null</td><td>null</td><td>null</td><td>27.718947</td><td>2.4515e6</td><td>104077.813356</td><td>null</td><td>1.054819</td><td>0.245864</td><td>0.455557</td><td>4.712994</td><td>1.854332</td><td>0.197039</td><td>0.022858</td><td>0.0727</td><td>0.045112</td><td>0.07854</td><td>0.177208</td><td>0.049567</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>17.635931</td><td>43.31605</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>59848.0</td><td>&quot;\u0010Canada is nor…</td><td>&quot;test&quot;</td><td>&quot;2015-09-29 10:…</td><td>2.0</td><td>61006.0</td><td>2006.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>0.0</td><td>3.0</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>856592.0</td><td>null</td><td>null</td><td>null</td><td>21.0</td><td>793011.0</td><td>160004.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>4.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>5.340251e6</td><td>null</td><td>null</td><td>null</td><td>54.0</td><td>5.217531e6</td><td>331925.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>4.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>5.95582e6</td><td>null</td><td>null</td><td>null</td><td>54.0</td><td>5.774684e6</td><td>366227.0</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>0.166667</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>6.0</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>7.5133e15</td><td>&quot;🤣gotta love it…</td><td>&quot;train&quot;</td><td>&quot;2017-11-11 01:…</td><td>115.0</td><td>6.333965e6</td><td>399544.0</td><td>&quot;rejected&quot;</td><td>102.0</td><td>21.0</td><td>31.0</td><td>300.0</td><td>187.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;0.75&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;0.75&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;0.6&quot;</td><td>1866.0</td><td>4936.0</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>&quot;1.0&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 51)\n",
       "┌────────────┬────────────┬────────────┬─────────┬───┬─────────┬────────────┬────────────┬─────────┐\n",
       "│ statistic  ┆ id         ┆ comment_te ┆ split   ┆ … ┆ toxic   ┆ severe_tox ┆ identity_h ┆ lang    │\n",
       "│ ---        ┆ ---        ┆ xt         ┆ ---     ┆   ┆ ---     ┆ ic         ┆ ate        ┆ ---     │\n",
       "│ str        ┆ f64        ┆ ---        ┆ str     ┆   ┆ str     ┆ ---        ┆ ---        ┆ str     │\n",
       "│            ┆            ┆ str        ┆         ┆   ┆         ┆ str        ┆ str        ┆         │\n",
       "╞════════════╪════════════╪════════════╪═════════╪═══╪═════════╪════════════╪════════════╪═════════╡\n",
       "│ count      ┆ 1.999561e6 ┆ 2047040    ┆ 1999516 ┆ … ┆ 47524   ┆ 47524      ┆ 47524      ┆ 0       │\n",
       "│ null_count ┆ 47480.0    ┆ 1          ┆ 47525   ┆ … ┆ 1999517 ┆ 1999517    ┆ 1999517    ┆ 2047041 │\n",
       "│ mean       ┆ 8.6318e10  ┆ null       ┆ null    ┆ … ┆ null    ┆ null       ┆ null       ┆ null    │\n",
       "│ std        ┆ 2.0846e13  ┆ null       ┆ null    ┆ … ┆ null    ┆ null       ┆ null       ┆ null    │\n",
       "│ min        ┆ 59848.0    ┆ \u0010Canada is  ┆ test    ┆ … ┆ 0.0     ┆ 0.0        ┆ 0.0        ┆ null    │\n",
       "│            ┆            ┆ north of   ┆         ┆   ┆         ┆            ┆            ┆         │\n",
       "│            ┆            ┆ the USA    ┆         ┆   ┆         ┆            ┆            ┆         │\n",
       "│            ┆            ┆ bord…      ┆         ┆   ┆         ┆            ┆            ┆         │\n",
       "│ 25%        ┆ 856592.0   ┆ null       ┆ null    ┆ … ┆ null    ┆ null       ┆ null       ┆ null    │\n",
       "│ 50%        ┆ 5.340251e6 ┆ null       ┆ null    ┆ … ┆ null    ┆ null       ┆ null       ┆ null    │\n",
       "│ 75%        ┆ 5.95582e6  ┆ null       ┆ null    ┆ … ┆ null    ┆ null       ┆ null       ┆ null    │\n",
       "│ max        ┆ 7.5133e15  ┆ 🤣gotta    ┆ train   ┆ … ┆ 1.0     ┆ 1.0        ┆ 1.0        ┆ null    │\n",
       "│            ┆            ┆ love it!   ┆         ┆   ┆         ┆            ┆            ┆         │\n",
       "└────────────┴────────────┴────────────┴─────────┴───┴─────────┴────────────┴────────────┴─────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.with_columns(pl.all().is_null().name.suffix(\"_isnull\")).count()  # nan != null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = df.select(\n",
    "    df[[\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",'sexual_explicit']]\n",
    "    ).max_horizontal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_047_041, 51)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>comment_text</th><th>split</th><th>created_date</th><th>publication_id</th><th>parent_id</th><th>article_id</th><th>rating</th><th>funny</th><th>wow</th><th>sad</th><th>likes</th><th>disagree</th><th>toxicity</th><th>severe_toxicity</th><th>obscene</th><th>sexual_explicit</th><th>identity_attack</th><th>insult</th><th>threat</th><th>male</th><th>female</th><th>transgender</th><th>other_gender</th><th>heterosexual</th><th>homosexual_gay_or_lesbian</th><th>bisexual</th><th>other_sexual_orientation</th><th>christian</th><th>jewish</th><th>muslim</th><th>hindu</th><th>buddhist</th><th>atheist</th><th>other_religion</th><th>black</th><th>white</th><th>asian</th><th>latino</th><th>other_race_or_ethnicity</th><th>physical_disability</th><th>intellectual_or_learning_disability</th><th>psychiatric_or_mental_illness</th><th>other_disability</th><th>identity_annotator_count</th><th>toxicity_annotator_count</th><th>toxic</th><th>severe_toxic</th><th>identity_hate</th><th>lang</th><th>max</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>1083994</td><td>&quot;He got his mon…</td><td>&quot;train&quot;</td><td>&quot;2017-03-06 15:…</td><td>21.0</td><td>null</td><td>317120.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>0.373134</td><td>0.044776</td><td>0.089552</td><td>0.014925</td><td>0.0</td><td>0.343284</td><td>0.014925</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>67.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.373134</td></tr><tr><td>650904</td><td>&quot;Mad dog will s…</td><td>&quot;train&quot;</td><td>&quot;2016-12-02 16:…</td><td>21.0</td><td>null</td><td>154086.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>1.0</td><td>2.0</td><td>0.0</td><td>0.605263</td><td>0.013158</td><td>0.065789</td><td>0.013158</td><td>0.092105</td><td>0.565789</td><td>0.065789</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>76.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.605263</td></tr><tr><td>5902188</td><td>&quot;And Trump cont…</td><td>&quot;train&quot;</td><td>&quot;2017-09-05 19:…</td><td>55.0</td><td>null</td><td>374342.0</td><td>&quot;approved&quot;</td><td>1.0</td><td>0.0</td><td>2.0</td><td>3.0</td><td>7.0</td><td>0.666667</td><td>0.015873</td><td>0.031746</td><td>0.0</td><td>0.047619</td><td>0.666667</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>63.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.666667</td></tr><tr><td>7084460</td><td>&quot;&quot;while arresti…</td><td>&quot;test&quot;</td><td>&quot;2016-11-01 16:…</td><td>13.0</td><td>null</td><td>149218.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.815789</td><td>0.065789</td><td>0.552632</td><td>0.592105</td><td>0.0</td><td>0.684211</td><td>0.105263</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>76.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.815789</td></tr><tr><td>5410943</td><td>&quot;Tucker and Pau…</td><td>&quot;train&quot;</td><td>&quot;2017-06-14 05:…</td><td>21.0</td><td>null</td><td>344096.0</td><td>&quot;approved&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.55</td><td>0.0375</td><td>0.3375</td><td>0.275</td><td>0.0375</td><td>0.4875</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>80.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.55</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>null</td><td>&quot;&quot;\n",
       "\n",
       " Ahirs (Abh…</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td><td>0.0</td></tr><tr><td>null</td><td>&quot;On User:Timoth…</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td><td>0.0</td></tr><tr><td>null</td><td>&quot;Thank you very…</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td><td>0.0</td></tr><tr><td>null</td><td>&quot;was hoping you…</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>&quot;0.0&quot;</td><td>null</td><td>0.0</td></tr><tr><td>null</td><td>&quot;&quot;\n",
       "\n",
       " Congratula…</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_047_041, 51)\n",
       "┌─────────┬──────────────┬───────┬──────────────┬───┬──────────────┬─────────────┬──────┬──────────┐\n",
       "│ id      ┆ comment_text ┆ split ┆ created_date ┆ … ┆ severe_toxic ┆ identity_ha ┆ lang ┆ max      │\n",
       "│ ---     ┆ ---          ┆ ---   ┆ ---          ┆   ┆ ---          ┆ te          ┆ ---  ┆ ---      │\n",
       "│ i64     ┆ str          ┆ str   ┆ str          ┆   ┆ str          ┆ ---         ┆ str  ┆ f64      │\n",
       "│         ┆              ┆       ┆              ┆   ┆              ┆ str         ┆      ┆          │\n",
       "╞═════════╪══════════════╪═══════╪══════════════╪═══╪══════════════╪═════════════╪══════╪══════════╡\n",
       "│ 1083994 ┆ He got his   ┆ train ┆ 2017-03-06   ┆ … ┆ null         ┆ null        ┆ null ┆ 0.373134 │\n",
       "│         ┆ money... now ┆       ┆ 15:21:53.675 ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ he lies …    ┆       ┆ 241+00       ┆   ┆              ┆             ┆      ┆          │\n",
       "│ 650904  ┆ Mad dog will ┆ train ┆ 2016-12-02   ┆ … ┆ null         ┆ null        ┆ null ┆ 0.605263 │\n",
       "│         ┆ surely put   ┆       ┆ 16:44:21.329 ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ the libe…    ┆       ┆ 535+00       ┆   ┆              ┆             ┆      ┆          │\n",
       "│ 5902188 ┆ And Trump    ┆ train ┆ 2017-09-05   ┆ … ┆ null         ┆ null        ┆ null ┆ 0.666667 │\n",
       "│         ┆ continues    ┆       ┆ 19:05:32.341 ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ his          ┆       ┆ 360+00       ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ lifelong…    ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│ 7084460 ┆ \"while       ┆ test  ┆ 2016-11-01   ┆ … ┆ null         ┆ null        ┆ null ┆ 0.815789 │\n",
       "│         ┆ arresting a  ┆       ┆ 16:53:33.561 ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ man for      ┆       ┆ 631+00       ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ resis…       ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│ 5410943 ┆ Tucker and   ┆ train ┆ 2017-06-14   ┆ … ┆ null         ┆ null        ┆ null ┆ 0.55     │\n",
       "│         ┆ Paul are     ┆       ┆ 05:08:21.997 ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ both total   ┆       ┆ 315+00       ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ b…           ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│ …       ┆ …            ┆ …     ┆ …            ┆ … ┆ …            ┆ …           ┆ …    ┆ …        │\n",
       "│ null    ┆ \"            ┆ null  ┆ null         ┆ … ┆ 0.0          ┆ 0.0         ┆ null ┆ 0.0      │\n",
       "│         ┆              ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ Ahirs        ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ (Abhiras)    ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ came from    ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ Ea…          ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│ null    ┆ On           ┆ null  ┆ null         ┆ … ┆ 0.0          ┆ 0.0         ┆ null ┆ 0.0      │\n",
       "│         ┆ User:Timothy ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ Usher        ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆              ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ Assalamu …   ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│ null    ┆ Thank you    ┆ null  ┆ null         ┆ … ┆ 0.0          ┆ 0.0         ┆ null ┆ 0.0      │\n",
       "│         ┆ very much.   ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ Since Ingle… ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│ null    ┆ was hoping   ┆ null  ┆ null         ┆ … ┆ 0.0          ┆ 0.0         ┆ null ┆ 0.0      │\n",
       "│         ┆ your the     ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ type of      ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ roug…        ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│ null    ┆ \"            ┆ null  ┆ null         ┆ … ┆ null         ┆ null        ┆ null ┆ null     │\n",
       "│         ┆              ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ Congratulati ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ ons. Here    ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "│         ┆ are wh…      ┆       ┆              ┆   ┆              ┆             ┆      ┆          │\n",
       "└─────────┴──────────────┴───────┴──────────────┴───┴──────────────┴─────────────┴──────┴──────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.with_columns(\n",
    "    df.select(\n",
    "    df[[\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",'sexual_explicit']]\n",
    "    ).max_horizontal()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polars import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"comment_text\", \"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",\"sexual_explicit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_047_041, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>comment_text</th><th>toxicity</th><th>severe_toxicity</th><th>obscene</th><th>threat</th><th>insult</th><th>identity_attack</th><th>sexual_explicit</th><th>sum</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;He got his mon…</td><td>0.373134</td><td>0.044776</td><td>0.089552</td><td>0.014925</td><td>0.343284</td><td>0.0</td><td>0.014925</td><td>0.373134</td></tr><tr><td>&quot;Mad dog will s…</td><td>0.605263</td><td>0.013158</td><td>0.065789</td><td>0.065789</td><td>0.565789</td><td>0.092105</td><td>0.013158</td><td>0.605263</td></tr><tr><td>&quot;And Trump cont…</td><td>0.666667</td><td>0.015873</td><td>0.031746</td><td>0.0</td><td>0.666667</td><td>0.047619</td><td>0.0</td><td>0.666667</td></tr><tr><td>&quot;&quot;while arresti…</td><td>0.815789</td><td>0.065789</td><td>0.552632</td><td>0.105263</td><td>0.684211</td><td>0.0</td><td>0.592105</td><td>0.815789</td></tr><tr><td>&quot;Tucker and Pau…</td><td>0.55</td><td>0.0375</td><td>0.3375</td><td>0.0</td><td>0.4875</td><td>0.0375</td><td>0.275</td><td>0.55</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;&quot;\n",
       "\n",
       " Ahirs (Abh…</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>&quot;On User:Timoth…</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>&quot;Thank you very…</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>&quot;was hoping you…</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>&quot;&quot;\n",
       "\n",
       " Congratula…</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_047_041, 9)\n",
       "┌────────────┬──────────┬────────────┬──────────┬───┬──────────┬────────────┬───────────┬──────────┐\n",
       "│ comment_te ┆ toxicity ┆ severe_tox ┆ obscene  ┆ … ┆ insult   ┆ identity_a ┆ sexual_ex ┆ sum      │\n",
       "│ xt         ┆ ---      ┆ icity      ┆ ---      ┆   ┆ ---      ┆ ttack      ┆ plicit    ┆ ---      │\n",
       "│ ---        ┆ f64      ┆ ---        ┆ f64      ┆   ┆ f64      ┆ ---        ┆ ---       ┆ f64      │\n",
       "│ str        ┆          ┆ f64        ┆          ┆   ┆          ┆ f64        ┆ f64       ┆          │\n",
       "╞════════════╪══════════╪════════════╪══════════╪═══╪══════════╪════════════╪═══════════╪══════════╡\n",
       "│ He got his ┆ 0.373134 ┆ 0.044776   ┆ 0.089552 ┆ … ┆ 0.343284 ┆ 0.0        ┆ 0.014925  ┆ 0.373134 │\n",
       "│ money...   ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ now he     ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ lies …     ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Mad dog    ┆ 0.605263 ┆ 0.013158   ┆ 0.065789 ┆ … ┆ 0.565789 ┆ 0.092105   ┆ 0.013158  ┆ 0.605263 │\n",
       "│ will       ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ surely put ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ the libe…  ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ And Trump  ┆ 0.666667 ┆ 0.015873   ┆ 0.031746 ┆ … ┆ 0.666667 ┆ 0.047619   ┆ 0.0       ┆ 0.666667 │\n",
       "│ continues  ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ his        ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ lifelong…  ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ \"while     ┆ 0.815789 ┆ 0.065789   ┆ 0.552632 ┆ … ┆ 0.684211 ┆ 0.0        ┆ 0.592105  ┆ 0.815789 │\n",
       "│ arresting  ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ a man for  ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ resis…     ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Tucker and ┆ 0.55     ┆ 0.0375     ┆ 0.3375   ┆ … ┆ 0.4875   ┆ 0.0375     ┆ 0.275     ┆ 0.55     │\n",
       "│ Paul are   ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ both total ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ b…         ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ …          ┆ …        ┆ …          ┆ …        ┆ … ┆ …        ┆ …          ┆ …         ┆ …        │\n",
       "│ \"          ┆ null     ┆ null       ┆ 0.0      ┆ … ┆ 0.0      ┆ null       ┆ null      ┆ 0.0      │\n",
       "│            ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Ahirs      ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ (Abhiras)  ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ came from  ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Ea…        ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ On User:Ti ┆ null     ┆ null       ┆ 0.0      ┆ … ┆ 0.0      ┆ null       ┆ null      ┆ 0.0      │\n",
       "│ mothy      ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Usher      ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│            ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Assalamu … ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Thank you  ┆ null     ┆ null       ┆ 0.0      ┆ … ┆ 0.0      ┆ null       ┆ null      ┆ 0.0      │\n",
       "│ very much. ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Since      ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Ingle…     ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ was hoping ┆ null     ┆ null       ┆ 0.0      ┆ … ┆ 0.0      ┆ null       ┆ null      ┆ 0.0      │\n",
       "│ your the   ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ type of    ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ roug…      ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ \"          ┆ null     ┆ null       ┆ null     ┆ … ┆ null     ┆ null       ┆ null      ┆ null     │\n",
       "│            ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Congratula ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ tions.     ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ Here are   ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "│ wh…        ┆          ┆            ┆          ┆   ┆          ┆            ┆           ┆          │\n",
       "└────────────┴──────────┴────────────┴──────────┴───┴──────────┴────────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_t_cols = [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",'sexual_explicit']\n",
    "\n",
    "df2.with_columns(\n",
    "    sum=pl.max_horizontal([df2[t] for t in temp_t_cols]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select(\"toxicity\").agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = df.select(\"toxicity\")\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.histplot(temp_df)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_df = pl.scan_csv(\"../data/raw/combined_jigsaw_comments.csv\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"340pt\" height=\"61pt\" viewBox=\"0.00 0.00 340.00 61.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 57)\">\n",
       "<title>polars_query</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-57 336,-57 336,4 -4,4\"/>\n",
       "<!-- [Csv SCAN ../data/raw/combined_jigsaw_comments.csv;\n",
       "π */50;\n",
       "σ &#45;] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>[Csv SCAN ../data/raw/combined_jigsaw_comments.csv;\n",
       "π */50;\n",
       "σ -]</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"332,-53 0,-53 0,0 332,0 332,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\">[Csv SCAN ../data/raw/combined_jigsaw_comments.csv;</text>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">π */50;</text>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">σ -]</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lazy_df.show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', Int64),\n",
       "             ('comment_text', String),\n",
       "             ('split', String),\n",
       "             ('created_date', String),\n",
       "             ('publication_id', Float64),\n",
       "             ('parent_id', Float64),\n",
       "             ('article_id', Float64),\n",
       "             ('rating', String),\n",
       "             ('funny', Float64),\n",
       "             ('wow', Float64),\n",
       "             ('sad', Float64),\n",
       "             ('likes', Float64),\n",
       "             ('disagree', Float64),\n",
       "             ('toxicity', Float64),\n",
       "             ('severe_toxicity', Float64),\n",
       "             ('obscene', Float64),\n",
       "             ('sexual_explicit', Float64),\n",
       "             ('identity_attack', Float64),\n",
       "             ('insult', Float64),\n",
       "             ('threat', Float64),\n",
       "             ('male', String),\n",
       "             ('female', String),\n",
       "             ('transgender', String),\n",
       "             ('other_gender', String),\n",
       "             ('heterosexual', String),\n",
       "             ('homosexual_gay_or_lesbian', String),\n",
       "             ('bisexual', String),\n",
       "             ('other_sexual_orientation', String),\n",
       "             ('christian', String),\n",
       "             ('jewish', String),\n",
       "             ('muslim', String),\n",
       "             ('hindu', String),\n",
       "             ('buddhist', String),\n",
       "             ('atheist', String),\n",
       "             ('other_religion', String),\n",
       "             ('black', String),\n",
       "             ('white', String),\n",
       "             ('asian', String),\n",
       "             ('latino', String),\n",
       "             ('other_race_or_ethnicity', String),\n",
       "             ('physical_disability', String),\n",
       "             ('intellectual_or_learning_disability', String),\n",
       "             ('psychiatric_or_mental_illness', String),\n",
       "             ('other_disability', String),\n",
       "             ('identity_annotator_count', Float64),\n",
       "             ('toxicity_annotator_count', Float64),\n",
       "             ('toxic', String),\n",
       "             ('severe_toxic', String),\n",
       "             ('identity_hate', String),\n",
       "             ('lang', String)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"comment_text\", \"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",\"sexual_explicit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "lazy_df = lazy_df.select(cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LazyFrame' object is not subscriptable (aside from slicing)\n\nUse `select()` or `filter()` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lazy_df \u001b[38;5;241m=\u001b[39m lazy_df\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m      2\u001b[0m     lazy_df\u001b[38;5;241m.\u001b[39mselect(\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mlazy_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoxicity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msevere_toxicity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobscene\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minsult\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43midentity_attack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msexual_explicit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m     )\u001b[38;5;241m.\u001b[39mcollect()\u001b[38;5;241m.\u001b[39mmax_horizontal()\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/polars/lazyframe/frame.py:760\u001b[0m, in \u001b[0;36mLazyFrame.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m    756\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    757\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLazyFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object is not subscriptable (aside from slicing)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUse `select()` or `filter()` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    759\u001b[0m     )\n\u001b[0;32m--> 760\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LazyPolarsSlice(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(item)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LazyFrame' object is not subscriptable (aside from slicing)\n\nUse `select()` or `filter()` instead."
     ]
    }
   ],
   "source": [
    "lazy_df = lazy_df.with_columns(\n",
    "    lazy_df.select(\n",
    "    lazy_df[[\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",'sexual_explicit']]\n",
    "    ).collect().max_horizontal().collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82255/3151280416.py:1: DtypeWarning: Columns (0,2,3,7,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../data/raw/combined_jigsaw_comments.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/raw/combined_jigsaw_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [\"comment_text\", \"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",\"sexual_explicit\"]\n",
    "cal_cols = [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",\"sexual_explicit\"]\n",
    "\n",
    "data = data[all_cols]\n",
    "\n",
    "# find max of rows\n",
    "# data[\"max_toxicity_score\"] = data[cal_cols].max(axis=1)\n",
    "# data = data.drop(columns=cal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He got his money... now he lies in wait till a...</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mad dog will surely put the liberals in mental...</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.013158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And Trump continues his lifelong cowardice by ...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"while arresting a man for resisting arrest\".\\...</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxicity  \\\n",
       "0  He got his money... now he lies in wait till a...  0.373134   \n",
       "1  Mad dog will surely put the liberals in mental...  0.605263   \n",
       "2  And Trump continues his lifelong cowardice by ...  0.666667   \n",
       "3  \"while arresting a man for resisting arrest\".\\...  0.815789   \n",
       "4     Tucker and Paul are both total bad ass mofo's.  0.550000   \n",
       "\n",
       "   severe_toxicity   obscene    threat    insult  identity_attack  \\\n",
       "0         0.044776  0.089552  0.014925  0.343284         0.000000   \n",
       "1         0.013158  0.065789  0.065789  0.565789         0.092105   \n",
       "2         0.015873  0.031746  0.000000  0.666667         0.047619   \n",
       "3         0.065789  0.552632  0.105263  0.684211         0.000000   \n",
       "4         0.037500  0.337500  0.000000  0.487500         0.037500   \n",
       "\n",
       "   sexual_explicit  \n",
       "0         0.014925  \n",
       "1         0.013158  \n",
       "2         0.000000  \n",
       "3         0.592105  \n",
       "4         0.275000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TextClassificationPipeline,\n",
    ")\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"martin-ha/toxic-comment-model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, max_length=\"max_length\", truncation=True, use_fast=True, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "# print(pipeline(\"This is a test text.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TextClassificationPipeline(model=model, tokenizer=tokenizer, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryangoh/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (721) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# def data():\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     for i in range(1000):\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#         yield f\"My example {i}\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# for out in pipe(data()):\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     generated_characters += len(out[0][\"generated_text\"])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# print(i,x)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_toxicity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/base.py:1196\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1190\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1193\u001b[0m         )\n\u001b[1;32m   1194\u001b[0m     )\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/base.py:1203\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1202\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1203\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/base.py:1102\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1101\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1102\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:186\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    185\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:1002\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1002\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:814\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    812\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 814\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[1;32m    817\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/toxic-comments-severity/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:156\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[0;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[1;32m    152\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m position_ids\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand_as(input_ids)  \u001b[38;5;66;03m# (bs, max_seq_length)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43minput_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    157\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    158\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (721) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# def data():\n",
    "#     for i in range(1000):\n",
    "#         yield f\"My example {i}\"\n",
    "\n",
    "\n",
    "# pipe = pipeline(model=\"openai-community/gpt2\", device=0)\n",
    "# generated_characters = 0\n",
    "# for out in pipe(data()):\n",
    "#     generated_characters += len(out[0][\"generated_text\"])\n",
    "\n",
    "for i in data[\"comment_text\"]:\n",
    "    x = pipeline(i)\n",
    "    # print(i,x)\n",
    "    data['predicted_toxicity'] = x[0][\"label\"]\n",
    "    data[\"predicted_non_toxicity_score\"] = x[0][\"score\"]\n",
    "    # print(x[0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KeyDataset is a util that will just output the item we're interested in.\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "pipe = pipeline(model=\"hf-internal-testing/tiny-random-wav2vec2\", device=0)\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:10]\")\n",
    "\n",
    "for out in pipe(KeyDataset(dataset, \"audio\")):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TextClassificationPipeline,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from torch import cuda\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import dill as pickle\n",
    "from huggingface_hub import login, notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicModeling:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model_path = \"distilbert/distilbert-base-uncased\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_path, num_labels=1\n",
    "        )\n",
    "        os.makedirs(\"./models/checkpoint\", exist_ok=True)\n",
    "        self.training_args = TrainingArguments(\n",
    "            output_dir=\"./models/checkpoint\", evaluation_strategy=\"epoch\"\n",
    "        )\n",
    "        self.metric = evaluate.load(\"mse\")\n",
    "        self.device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def tokenize_function(self, example):\n",
    "        # dataset[target_col] = dataset[target_col].astype(str)\n",
    "        return self.tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    # def _tokenize(self, dataset):\n",
    "    #     return dataset.map(self.tokenize_function, batched=True)\n",
    "\n",
    "    def _compute_metrics(self, eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        # predictions = np.argmax(logits, axis=-1)\n",
    "        predictions = logits\n",
    "        return self.metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_dataset,\n",
    "        eval_dataset,\n",
    "        target_col,\n",
    "    ):\n",
    "        # tokenized_train_function = self.tokenize_function(train_dataset, target_col)\n",
    "        # tokenized_eval_function = self.tokenize_function(eval_dataset, target_col)\n",
    "        # tokenized_function = self.tokenize_function\n",
    "        # tokenized_train_dataset = train_dataset.map(\n",
    "        #     self.tokenize_function, batched=True\n",
    "        # )\n",
    "        # tokenized_eval_dataset = eval_dataset.map(self.tokenize_function, batched=True)\n",
    "\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=self.training_args,\n",
    "            train_dataset=tokenized_train_dataset,\n",
    "            eval_dataset=tokenized_eval_dataset,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "            push_to_hub=True,\n",
    "            data_collator=self.data_collator,\n",
    "        )\n",
    "        trainer.train()\n",
    "        return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/train.pkl\", \"rb\") as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "f.close()\n",
    "with open(\"../data/processed/test.pkl\", \"rb\") as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_54687/1920291564.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  train_dataset = train_dataset.applymap(str)\n",
      "/tmp/ipykernel_54687/1920291564.py:4: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  test_dataset = test_dataset.applymap(str)\n"
     ]
    }
   ],
   "source": [
    "# notebook_login()\n",
    "tx = ToxicModeling()\n",
    "train_dataset = train_dataset.applymap(str)\n",
    "test_dataset = test_dataset.applymap(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoxicity_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoxicity_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      2\u001b[0m test_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoxicity_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m test_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoxicity_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39mmap(tx\u001b[38;5;241m.\u001b[39mtokenize_function)\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10455\u001b[0m, in \u001b[0;36mDataFrame.map\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[1;32m  10453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m> 10455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10360\u001b[0m )\n\u001b[0;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10453\u001b[0m, in \u001b[0;36mDataFrame.map.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m  10452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[0;32m> 10453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIAP/toxic_comments_severity/.venv/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mToxicModeling.tokenize_function\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, example):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# dataset[target_col] = dataset[target_col].astype(str)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "train_dataset[\"toxicity_score\"] = train_dataset[\"toxicity_score\"].astype(float)\n",
    "test_dataset[\"toxicity_score\"] = test_dataset[\"toxicity_score\"].astype(float)\n",
    "train_dataset = train_dataset.map(tx.tokenize_function)\n",
    "test_dataset = test_dataset.map(tx.tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = train_dataset.sample(10)\n",
    "test_dataset = test_dataset.sample(10)\n",
    "tx.train(\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    target_col=args[\"target_col\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
